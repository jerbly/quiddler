{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.13.0 to work with jbWorkspace\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: quiddler_model, Version: 1\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['quiddler_model']\n",
    "print(f'Model: {model.name}, Version: {model.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source/inference-env.yml'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"icevision[all]==0.1.4\")\n",
    "myenv.add_pip_package(\"inference-schema\")\n",
    "myenv.add_pip_package(\"pygtrie\")\n",
    "myenv.save('source/inference-env.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = 'source',\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"inference-env.yml\")\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration()\n",
    "\n",
    "service_name = \"quiddler-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32795\n"
     ]
    }
   ],
   "source": [
    "service.reload(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:32795/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g/th/in/p/u', 'a', [[32, True, [['g/u/p', [16, 3, ['g', 'u', 'p']]], ['th/in', [16, 2, ['th', 'in']]]]], 'a', 'a']]\n",
      "\n",
      "Hand:     g/th/in/p/u\n",
      "Deck:     a\n",
      "Score:    32\n",
      "Complete: True\n",
      "Words:    ['g/u/p', 'th/in']\n",
      "Pick up:  a\n",
      "Drop:     a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSON DATA\n",
    "import base64\n",
    "import requests\n",
    "import json \n",
    "\n",
    "def get_base64_encoded_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "input_json = json.dumps({\n",
    "    \"n_cards\": 5,\n",
    "    \"hand\": get_base64_encoded_image('/home/jeremy/Documents/data/quiddler/test/IMG_4903.jpg'),\n",
    "    \"deck\": get_base64_encoded_image('/home/jeremy/Documents/data/quiddler/train/A_1.jpg')\n",
    "})\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "p = predictions.json()\n",
    "print(str(p)+'\\n')\n",
    "print(f'Hand:     {p[0]}')\n",
    "print(f'Deck:     {p[1]}')\n",
    "if len(p) > 2:\n",
    "    play = p[2][0]\n",
    "    print(f'Score:    {play[0]}')\n",
    "    print(f'Complete: {play[1]}')\n",
    "    print(f'Words:    {[c[0] for c in play[2]]}')\n",
    "    print(f'Pick up:  {p[2][1]}')\n",
    "    print(f'Drop:     {p[2][2]}\\n')\n",
    "else:\n",
    "    print('No possible play for these cards')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container (name:charming_kilby, id:4fb08ec1fab48473dae41dbaf136485c149141070ee1117e46ceb74c621c7db6) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Service deleted.\n"
     ]
    }
   ],
   "source": [
    "service.delete()\n",
    "print(\"Service deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy into AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = 'source',\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"inference-env.yml\")\n",
    "service_name = \"quiddler-service2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute\n",
    "\n",
    "aks_target = AksCompute(ws,\"jb-inf\")\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary, secondary = service.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# URL for the web service\n",
    "endpoint = service.scoring_uri\n",
    "# If the service is authenticated, set the key or token\n",
    "key = primary\n",
    "\n",
    "def get_base64_encoded_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "b64img = get_base64_encoded_image('/home/jeremy/Documents/data/quiddler/test/IMG_4907.jpg')\n",
    "input_json = json.dumps({\"n_cards\": 11, \"hand\": b64img})\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "print(predictions.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
