{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference testing function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import json \n",
    "\n",
    "def get_base64_encoded_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "def test_inf(endpoint, key=None):\n",
    "    input_json = json.dumps({\n",
    "        \"n_cards\": 5,\n",
    "        \"images\": True,\n",
    "        \"hand\": get_base64_encoded_image('/home/jeremy/Documents/data/quiddler/test/IMG_4903.jpg'),\n",
    "        \"deck\": get_base64_encoded_image('/home/jeremy/Documents/data/quiddler/train/A_1.jpg')\n",
    "    })\n",
    "    headers = { 'Content-Type':'application/json' }\n",
    "    if key:\n",
    "        headers['Authorization'] = f'Bearer {key}' # Only difference to local is to send the auth key\n",
    "    predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "    p = predictions.json()\n",
    "    print(str(p)+'\\n')\n",
    "    print(f'Hand:     {p[0]}')\n",
    "    print(f'Deck:     {p[1]}')\n",
    "    if p[2]:\n",
    "        play = p[2][0]\n",
    "        print(f'Score:    {play[0]}')\n",
    "        print(f'Complete: {play[1]}')\n",
    "        print(f'Words:    {[c[0] for c in play[2]]}')\n",
    "        print(f'Pick up:  {p[2][1]}')\n",
    "        print(f'Drop:     {p[2][2]}\\n')\n",
    "    else:\n",
    "        print('No possible play for these cards')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML version: 1.13.0, Workspace: jbWorkspace\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print(f'Azure ML version: {azureml.core.VERSION}, Workspace: {ws.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the inference conda file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source/inference-env.yml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"icevision[all]==0.1.4\")\n",
    "myenv.add_pip_package(\"inference-schema\")\n",
    "myenv.add_pip_package(\"pygtrie\")\n",
    "myenv.save('source/inference-env.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: quiddler_model, Version: 1\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['quiddler_model']\n",
    "print(f'Model: {model.name}, Version: {model.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = 'source',\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"inference-env.yml\")\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration()\n",
    "\n",
    "service_name = \"quiddler-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32779\n"
     ]
    }
   ],
   "source": [
    "# Reload the service to pick up changes in the source directory\n",
    "service.reload(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:32779/score\n"
     ]
    }
   ],
   "source": [
    "local_endpoint = service.scoring_uri\n",
    "print(local_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g/th/in/p/u', 'a', [[32, True, [['g/u/p', [16, 3, ['g', 'u', 'p']]], ['th/in', [16, 2, ['th', 'in']]]]], 'a', 'a']]\n",
      "\n",
      "Hand:     g/th/in/p/u\n",
      "Deck:     a\n",
      "Score:    32\n",
      "Complete: True\n",
      "Words:    ['g/u/p', 'th/in']\n",
      "Pick up:  a\n",
      "Drop:     a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inf(local_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n",
      "Service deleted.\n"
     ]
    }
   ],
   "source": [
    "service.delete()\n",
    "print(\"Service deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n"
     ]
    }
   ],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy into AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute\n",
    "\n",
    "service_name = \"quiddler-service2\"\n",
    "aks_target = AksCompute(ws,\"jb-inf\")\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "aks_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, aks_target)\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)\n",
    "#print(aks_service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.177.13.18:80/api/v1/service/quiddler-service2/score\n"
     ]
    }
   ],
   "source": [
    "primary, secondary = aks_service.get_keys()\n",
    "aks_endpoint = aks_service.scoring_uri\n",
    "print(aks_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g/th/in/p/u', 'a', [[32, True, [['g/u/p', [16, 3, ['g', 'u', 'p']]], ['th/in', [16, 2, ['th', 'in']]]]], 'a', 'a']]\n",
      "\n",
      "Hand:     g/th/in/p/u\n",
      "Deck:     a\n",
      "Score:    32\n",
      "Complete: True\n",
      "Words:    ['g/u/p', 'th/in']\n",
      "Pick up:  a\n",
      "Drop:     a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inf(aks_endpoint, primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
